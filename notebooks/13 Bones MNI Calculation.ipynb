{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7fd18da-7155-4b21-b090-dd07a902c99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.9/250.9 kB\u001b[0m \u001b[31m498.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a79723",
   "metadata": {},
   "source": [
    "# MNI Calculation\n",
    "\n",
    "This notebook prepares data for MNI calculation and writes the results to the `source_data.xlsx` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b194084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from scripts.mni import calculate_mni\n",
    "\n",
    "# Load source data and normalise column names\n",
    "df_occurrences = pd.read_pickle('../data/pkl/df_occurrences.pkl')\n",
    "df_briana_with_responses = pd.read_pickle('../data/pkl/df_briana_with_responses.pkl')\n",
    "df_occurrences.columns = df_occurrences.columns.str.strip()\n",
    "df_briana_with_responses.columns = df_briana_with_responses.columns.str.strip()\n",
    "\n",
    "# Coerce identifiers to integers\n",
    "df_occurrences['ID'] = pd.to_numeric(df_occurrences['ID'], errors='coerce').astype('Int64')\n",
    "df_briana_with_responses['OccurrenceID'] = pd.to_numeric(df_briana_with_responses['OccurrenceID'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Ensure a populated 'Taxon Label' column exists\n",
    "if 'Taxon Label' not in df_occurrences.columns or df_occurrences['Taxon Label'].isna().all():\n",
    "    df_occurrences['Taxon Label'] = pd.NA\n",
    "    for c in ['Post: Taxon Guess?', 'Pre: Taxon']:\n",
    "        if c in df_occurrences.columns:\n",
    "            df_occurrences['Taxon Label'] = df_occurrences['Taxon Label'].fillna(df_occurrences[c])\n",
    "\n",
    "# Select required columns from each table\n",
    "columns_occurrences = ['ID', 'TransectUID', 'Taxon Label', 'Pre: Sex', 'Pre: Age']\n",
    "columns_briana = ['OccurrenceID', 'Weathering class', 'What element is this?', 'Side', 'Complete', 'Complete?']\n",
    "df_occurrences = df_occurrences.reindex(columns=columns_occurrences)\n",
    "df_briana_with_responses = df_briana_with_responses.reindex(columns=columns_briana)\n",
    "\n",
    "# Fill missing 'Complete?' values with fallback from 'Complete'\n",
    "df_briana_with_responses['Complete?'] = (\n",
    "    df_briana_with_responses['Complete?']\n",
    "    .replace(r'^\\s*$', pd.NA, regex=True)\n",
    "    .fillna(df_briana_with_responses['Complete'])\n",
    ")\n",
    "df_briana_with_responses = df_briana_with_responses.drop(columns=['Complete'])\n",
    "\n",
    "# Merge and keep OccurrenceID for later grouping\n",
    "df = (\n",
    "    df_occurrences\n",
    "    .merge(\n",
    "        df_briana_with_responses,\n",
    "        left_on='ID',\n",
    "        right_on='OccurrenceID',\n",
    "        how='left',\n",
    "    )\n",
    "    .drop(columns=['ID'])\n",
    ")\n",
    "df['TransectUID'] = pd.to_numeric(df['TransectUID'], errors='coerce').astype('Int64')\n",
    "\n",
    "# For each OccurrenceID, retain the highest weathering class\n",
    "import re\n",
    "def _wx_score(val):\n",
    "    nums = re.findall(r'\\d+', str(val))\n",
    "    return max(map(int, nums)) if nums else -1\n",
    "df['Weathering class'] = (\n",
    "    df.groupby('OccurrenceID')['Weathering class']\n",
    "    .transform(lambda s: s.loc[s.map(_wx_score).idxmax()])\n",
    ")\n",
    "\n",
    "# Keep all completed rows; for incomplete elements, drop duplicate entries across key fields\n",
    "non_no = df[df['Complete?'] != 'No']\n",
    "subset_cols = [\n",
    "    'TransectUID',\n",
    "    'OccurrenceID',\n",
    "    'Taxon Label',\n",
    "    'Pre: Sex',\n",
    "    'Pre: Age',\n",
    "    'Weathering class',\n",
    "    'What element is this?',\n",
    "    'Side',\n",
    "]\n",
    "no_rows = df[df['Complete?'] == 'No'].drop_duplicates(subset=subset_cols)\n",
    "df = pd.concat([non_no, no_rows], ignore_index=True)\n",
    "\n",
    "# Drop helper columns\n",
    "df = df.drop(columns=['OccurrenceID', 'Complete?'])\n",
    "\n",
    "# Remove high-level and other taxa not needed for MNI\n",
    "df = df[~df['Taxon Label'].str.lower().isin(['mammalia indet', 'ungulate', 'ostrich', 'Aves (medium)', 'Aves (small)'])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ccbe37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot side counts by transect, taxon, sex, age, weathering class, and element\n",
    "pivot_df = (\n",
    "    df.pivot_table(\n",
    "        index=[\"TransectUID\", \"Taxon Label\", \"Pre: Sex\", \"Pre: Age\", \"Weathering class\", \"What element is this?\"],\n",
    "        columns=\"Side\",\n",
    "        aggfunc=\"size\",\n",
    "        fill_value=0,\n",
    "    )\n",
    "    .rename_axis(columns=None)\n",
    "    .reset_index()\n",
    ")\n",
    "pivot_df[\"TransectUID\"] = pd.to_numeric(pivot_df[\"TransectUID\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# Split counts for observations with unknown side evenly between left and right\n",
    "if \"unknown\" in pivot_df.columns:\n",
    "    pivot_df[\"unknown\"] = np.ceil(pivot_df[\"unknown\"] / 2).astype(int)\n",
    "\n",
    "pivot_df.head()\n",
    "from pathlib import Path\n",
    "pivot_output_path = Path(\"../data/export/excel/pivot_df.xlsx\")\n",
    "pivot_output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "pivot_df.to_excel(pivot_output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecc9d0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mni_per_transect, group_mni = calculate_mni(pivot_df)\n",
    "mni_per_transect\n",
    "mni_per_transect_output_path = Path(\"../data/export/excel/mni_per_transect_df.xlsx\")\n",
    "mni_per_transect_output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "mni_per_transect.to_excel(mni_per_transect_output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9569c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "output_path = Path(\"../data/export/excel/source_data.xlsx\")\n",
    "if output_path.exists():\n",
    "    transect_sheet = pd.read_excel(output_path, sheet_name=\"Transects\")\n",
    "else:\n",
    "    transect_sheet = pd.DataFrame(columns=[\"TransectUID\"])\n",
    "\n",
    "if \"TransectUID\" not in transect_sheet.columns:\n",
    "    if \"UID\" in transect_sheet.columns:\n",
    "        transect_sheet = transect_sheet.rename(columns={\"UID\": \"TransectUID\"})\n",
    "    else:\n",
    "        transect_sheet[\"TransectUID\"] = pd.NA\n",
    "\n",
    "transect_sheet[\"TransectUID\"] = pd.to_numeric(transect_sheet[\"TransectUID\"], errors=\"coerce\").astype(\"Int64\")\n",
    "mni_per_transect[\"TransectUID\"] = pd.to_numeric(mni_per_transect[\"TransectUID\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "transect_sheet = transect_sheet.merge(mni_per_transect, on=\"TransectUID\", how=\"left\")\n",
    "transect_sheet = transect_sheet.rename(columns={\"MNI\": \"MNI_calc\"})\n",
    "\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "if output_path.exists():\n",
    "    with pd.ExcelWriter(output_path, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
    "        transect_sheet.to_excel(writer, sheet_name=\"Transects\", index=False)\n",
    "        group_mni.to_excel(writer, sheet_name=\"Group MNI\", index=False)\n",
    "else:\n",
    "    with pd.ExcelWriter(output_path, engine=\"openpyxl\") as writer:\n",
    "        transect_sheet.to_excel(writer, sheet_name=\"Transects\", index=False)\n",
    "        group_mni.to_excel(writer, sheet_name=\"Group MNI\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70205c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numbers\n",
    "\n",
    "EXCLUDED_MNI_TAXA = {\"Aves (medium)\", \"Aves (small)\", \"Mammalia indet.\", \"Ungulata\"}\n",
    "habitats = [\"grass closed\", \"shrubs open\", \"shrubs closed\", \"trees closed\"]\n",
    "total_label = \"eastern OPC\"\n",
    "\n",
    "transects = pd.read_pickle(\"../data/pkl/df_transects.pkl\")\n",
    "transects.columns = transects.columns.str.strip()\n",
    "transect_meta = (\n",
    "    transects[[\"UID\", \"Pre: On old reserve?\", \"Pre: Transect physical habitat\"]]\n",
    "    .rename(columns={\"UID\": \"TransectUID\"})\n",
    "    .dropna(subset=[\"TransectUID\"])\n",
    ")\n",
    "transect_meta[\"TransectUID\"] = pd.to_numeric(\n",
    "    transect_meta[\"TransectUID\"], errors=\"coerce\"\n",
    ").astype(\"Int64\")\n",
    "transect_meta[\"habitat\"] = (\n",
    "    transect_meta[\"Pre: Transect physical habitat\"].astype(str).str.strip().str.lower()\n",
    ")\n",
    "\n",
    "def _safe_int(value):\n",
    "    return int(value) if pd.notna(value) else 0\n",
    "\n",
    "occurrences_enriched = (\n",
    "    df_occurrences\n",
    "    .merge(transect_meta, on=\"TransectUID\", how=\"left\")\n",
    "    .dropna(subset=[\"Taxon Label\", \"habitat\", \"Pre: On old reserve?\"])\n",
    ")\n",
    "occurrences_enriched = occurrences_enriched[\n",
    "    occurrences_enriched[\"Pre: On old reserve?\"] == \"Yes\"\n",
    "]\n",
    "occurrences_enriched = occurrences_enriched[\n",
    "    occurrences_enriched[\"habitat\"].isin(habitats)\n",
    "]\n",
    "\n",
    "occ_total_species = occurrences_enriched.groupby(\"Taxon Label\").size()\n",
    "occ_total_all = int(occ_total_species.sum()) if not occ_total_species.empty else 0\n",
    "occ_total_percent = (\n",
    "    occ_total_species.div(occ_total_all).mul(100)\n",
    "    if occ_total_all\n",
    "    else occ_total_species.astype(float)\n",
    ").replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "occ_by_hab_species = occurrences_enriched.groupby([\"Taxon Label\", \"habitat\"]).size()\n",
    "occ_total_by_hab = occurrences_enriched.groupby(\"habitat\").size()\n",
    "occ_percent_by_hab = (\n",
    "    occ_by_hab_species.div(occ_total_by_hab, level=\"habitat\").mul(100)\n",
    "    if not occ_total_by_hab.empty\n",
    "    else occ_by_hab_species.astype(float)\n",
    ").replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "mni_enriched = (\n",
    "    group_mni\n",
    "    .merge(transect_meta, on=\"TransectUID\", how=\"left\")\n",
    "    .dropna(subset=[\"Taxon\", \"habitat\", \"Pre: On old reserve?\"])\n",
    ")\n",
    "mni_enriched = mni_enriched[mni_enriched[\"Pre: On old reserve?\"] == \"Yes\"]\n",
    "mni_enriched = mni_enriched[mni_enriched[\"habitat\"].isin(habitats)]\n",
    "mni_enriched = mni_enriched[~mni_enriched[\"Taxon\"].isin(EXCLUDED_MNI_TAXA)]\n",
    "\n",
    "mni_total_species = mni_enriched.groupby(\"Taxon\")[\"Group MNI\"].sum()\n",
    "mni_total_all = int(mni_total_species.sum()) if not mni_total_species.empty else 0\n",
    "mni_total_percent = (\n",
    "    mni_total_species.div(mni_total_all).mul(100)\n",
    "    if mni_total_all\n",
    "    else mni_total_species.astype(float)\n",
    ").replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "mni_by_hab_species = mni_enriched.groupby([\"Taxon\", \"habitat\"])[\"Group MNI\"].sum()\n",
    "mni_total_by_hab = mni_enriched.groupby(\"habitat\")[\"Group MNI\"].sum()\n",
    "mni_percent_by_hab = (\n",
    "    mni_by_hab_species.div(mni_total_by_hab, level=\"habitat\").mul(100)\n",
    "    if not mni_total_by_hab.empty\n",
    "    else mni_by_hab_species.astype(float)\n",
    ").replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "column_tuples = []\n",
    "for habitat in [total_label] + habitats:\n",
    "    for metric in [\"Occurrence\", \"MNI\"]:\n",
    "        for stat in [\"n\", \"%\"]:\n",
    "            column_tuples.append((habitat, metric, stat))\n",
    "columns = pd.MultiIndex.from_tuples(\n",
    "    column_tuples, names=[\"Habitat\", \"Measure\", \"Statistic\"]\n",
    ")\n",
    "\n",
    "species_order = occ_total_species.sort_values(ascending=False).index.tolist()\n",
    "for taxon in mni_total_species.index:\n",
    "    if taxon not in species_order:\n",
    "        species_order.append(taxon)\n",
    "\n",
    "summary_rows = []\n",
    "for taxon in species_order:\n",
    "    row = {}\n",
    "    occ_total_value = occ_total_species.get(taxon, 0)\n",
    "    row[(total_label, \"Occurrence\", \"n\")] = _safe_int(occ_total_value)\n",
    "    row[(total_label, \"Occurrence\", \"%\")] = occ_total_percent.get(taxon, 0.0)\n",
    "    if taxon in EXCLUDED_MNI_TAXA:\n",
    "        row[(total_label, \"MNI\", \"n\")] = pd.NA\n",
    "        row[(total_label, \"MNI\", \"%\")] = pd.NA\n",
    "    else:\n",
    "        mni_total_value = mni_total_species.get(taxon, 0)\n",
    "        row[(total_label, \"MNI\", \"n\")] = _safe_int(mni_total_value)\n",
    "        row[(total_label, \"MNI\", \"%\")] = mni_total_percent.get(taxon, 0.0)\n",
    "    for habitat in habitats:\n",
    "        occ_hab_value = occ_by_hab_species.get((taxon, habitat), 0)\n",
    "        row[(habitat, \"Occurrence\", \"n\")] = _safe_int(occ_hab_value)\n",
    "        row[(habitat, \"Occurrence\", \"%\")] = occ_percent_by_hab.get((taxon, habitat), 0.0)\n",
    "        if taxon in EXCLUDED_MNI_TAXA:\n",
    "            row[(habitat, \"MNI\", \"n\")] = pd.NA\n",
    "            row[(habitat, \"MNI\", \"%\")] = pd.NA\n",
    "        else:\n",
    "            mni_hab_value = mni_by_hab_species.get((taxon, habitat), 0)\n",
    "            row[(habitat, \"MNI\", \"n\")] = _safe_int(mni_hab_value)\n",
    "            row[(habitat, \"MNI\", \"%\")] = mni_percent_by_hab.get((taxon, habitat), 0.0)\n",
    "    summary_rows.append(row)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows, index=species_order, columns=columns)\n",
    "summary_df.index.name = \"Species\"\n",
    "\n",
    "percent_columns = [col for col in summary_df.columns if col[2] == \"%\"]\n",
    "count_columns = [col for col in summary_df.columns if col[2] == \"n\"]\n",
    "\n",
    "summary_df[percent_columns] = summary_df[percent_columns].applymap(\n",
    "    lambda x: round(float(x), 2) if isinstance(x, numbers.Real) and not pd.isna(x) else x\n",
    ")\n",
    "summary_df[count_columns] = summary_df[count_columns].applymap(\n",
    "    lambda x: int(x) if isinstance(x, numbers.Real) and not pd.isna(x) else x\n",
    ")\n",
    "\n",
    "total_row = {}\n",
    "total_row[(total_label, \"Occurrence\", \"n\")] = occ_total_all\n",
    "total_row[(total_label, \"Occurrence\", \"%\")] = 100.0 if occ_total_all else 0.0\n",
    "total_row[(total_label, \"MNI\", \"n\")] = mni_total_all\n",
    "total_row[(total_label, \"MNI\", \"%\")] = 100.0 if mni_total_all else 0.0\n",
    "for habitat in habitats:\n",
    "    occ_total_hab = _safe_int(occ_total_by_hab.get(habitat, 0))\n",
    "    mni_total_hab = _safe_int(mni_total_by_hab.get(habitat, 0))\n",
    "    total_row[(habitat, \"Occurrence\", \"n\")] = occ_total_hab\n",
    "    total_row[(habitat, \"Occurrence\", \"%\")] = 100.0 if occ_total_hab else 0.0\n",
    "    total_row[(habitat, \"MNI\", \"n\")] = mni_total_hab\n",
    "    total_row[(habitat, \"MNI\", \"%\")] = 100.0 if mni_total_hab else 0.0\n",
    "\n",
    "total_df = pd.DataFrame([total_row], index=[\"Total occurrences\"], columns=columns)\n",
    "summary_df = pd.concat([total_df, summary_df])\n",
    "\n",
    "output_path = Path(\"../data/export/excel/mni_occurrence_summary_by_habitat.xlsx\")\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "summary_df.to_excel(output_path, sheet_name=\"Summary\", merge_cells=False)\n",
    "\n",
    "summary_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
