{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56a79723",
   "metadata": {},
   "source": [
    "# MNI Calculation\n",
    "\n",
    "This notebook prepares data for MNI calculation and writes the results to the `source_data.xlsx` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b194084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from scripts.mni import calculate_mni\n",
    "\n",
    "# Load source data and normalise column names\n",
    "df_occurrences = pd.read_pickle('../data/pkl/df_occurrences.pkl')\n",
    "df_briana_with_responses = pd.read_pickle('../data/pkl/df_briana_with_responses.pkl')\n",
    "df_occurrences.columns = df_occurrences.columns.str.strip()\n",
    "df_briana_with_responses.columns = df_briana_with_responses.columns.str.strip()\n",
    "\n",
    "# Coerce identifiers to integers\n",
    "df_occurrences['ID'] = pd.to_numeric(df_occurrences['ID'], errors='coerce').astype('Int64')\n",
    "df_briana_with_responses['OccurrenceID'] = pd.to_numeric(df_briana_with_responses['OccurrenceID'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Ensure a populated 'Taxon Label' column exists\n",
    "if 'Taxon Label' not in df_occurrences.columns or df_occurrences['Taxon Label'].isna().all():\n",
    "    df_occurrences['Taxon Label'] = pd.NA\n",
    "    for c in ['Post: Taxon Guess?', 'Pre: Taxon']:\n",
    "        if c in df_occurrences.columns:\n",
    "            df_occurrences['Taxon Label'] = df_occurrences['Taxon Label'].fillna(df_occurrences[c])\n",
    "\n",
    "# Select required columns from each table\n",
    "columns_occurrences = ['ID', 'TransectUID', 'Taxon Label', 'Pre: Sex', 'Pre: Age']\n",
    "columns_briana = ['OccurrenceID', 'Weathering class', 'What element is this?', 'Side', 'Complete', 'Complete?']\n",
    "df_occurrences = df_occurrences.reindex(columns=columns_occurrences)\n",
    "df_briana_with_responses = df_briana_with_responses.reindex(columns=columns_briana)\n",
    "\n",
    "# Fill missing 'Complete?' values with fallback from 'Complete'\n",
    "df_briana_with_responses['Complete?'] = (\n",
    "    df_briana_with_responses['Complete?']\n",
    "    .replace(r'^\\s*$', pd.NA, regex=True)\n",
    "    .fillna(df_briana_with_responses['Complete'])\n",
    ")\n",
    "df_briana_with_responses = df_briana_with_responses.drop(columns=['Complete'])\n",
    "\n",
    "# Merge and keep OccurrenceID for later grouping\n",
    "df = (\n",
    "    df_occurrences\n",
    "    .merge(\n",
    "        df_briana_with_responses,\n",
    "        left_on='ID',\n",
    "        right_on='OccurrenceID',\n",
    "        how='left',\n",
    "    )\n",
    "    .drop(columns=['ID'])\n",
    ")\n",
    "df['TransectUID'] = pd.to_numeric(df['TransectUID'], errors='coerce').astype('Int64')\n",
    "\n",
    "# For each OccurrenceID, retain the highest weathering class\n",
    "import re\n",
    "def _wx_score(val):\n",
    "    nums = re.findall(r'\\d+', str(val))\n",
    "    return max(map(int, nums)) if nums else -1\n",
    "df['Weathering class'] = (\n",
    "    df.groupby('OccurrenceID')['Weathering class']\n",
    "    .transform(lambda s: s.loc[s.map(_wx_score).idxmax()])\n",
    ")\n",
    "\n",
    "# Keep all completed rows; for incomplete surveys, drop duplicate entries across key fields\n",
    "non_no = df[df['Complete?'] != 'No']\n",
    "subset_cols = [\n",
    "    'TransectUID',\n",
    "    'OccurrenceID',\n",
    "    'Taxon Label',\n",
    "    'Pre: Sex',\n",
    "    'Pre: Age',\n",
    "    'Weathering class',\n",
    "    'What element is this?',\n",
    "    'Side',\n",
    "]\n",
    "no_rows = df[df['Complete?'] == 'No'].drop_duplicates(subset=subset_cols)\n",
    "df = pd.concat([non_no, no_rows], ignore_index=True)\n",
    "\n",
    "# Drop helper columns\n",
    "df = df.drop(columns=['OccurrenceID', 'Complete?'])\n",
    "\n",
    "# Remove high-level taxa not needed for MNI\n",
    "df = df[~df['Taxon Label'].str.lower().isin(['mammalia indet', 'ungulate'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccbe37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot side counts by transect, taxon, sex, age, weathering class, and element\n",
    "pivot_df = (\n",
    "    df.pivot_table(\n",
    "        index=[\"TransectUID\", \"Taxon Label\", \"Pre: Sex\", \"Pre: Age\", \"Weathering class\", \"What element is this?\"],\n",
    "        columns=\"Side\",\n",
    "        aggfunc=\"size\",\n",
    "        fill_value=0,\n",
    "    )\n",
    "    .rename_axis(columns=None)\n",
    "    .reset_index()\n",
    ")\n",
    "pivot_df[\"TransectUID\"] = pd.to_numeric(pivot_df[\"TransectUID\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# Split counts for observations with unknown side evenly between left and right\n",
    "if \"unknown\" in pivot_df.columns:\n",
    "    pivot_df[\"unknown\"] = np.ceil(pivot_df[\"unknown\"] / 2).astype(int)\n",
    "\n",
    "pivot_df.head()\n",
    "from pathlib import Path\n",
    "pivot_output_path = Path(\"../data/export/excel/pivot_df.xlsx\")\n",
    "pivot_output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "pivot_df.to_excel(pivot_output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc9d0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mni_per_transect = calculate_mni(pivot_df)\n",
    "mni_per_transect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9569c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "output_path = Path(\"../data/export/excel/source_data.xlsx\")\n",
    "if output_path.exists():\n",
    "    transect_sheet = pd.read_excel(output_path, sheet_name=\"Transects\")\n",
    "else:\n",
    "    transect_sheet = pd.DataFrame(columns=[\"TransectUID\"])\n",
    "\n",
    "if \"TransectUID\" not in transect_sheet.columns:\n",
    "    if \"UID\" in transect_sheet.columns:\n",
    "        transect_sheet = transect_sheet.rename(columns={\"UID\": \"TransectUID\"})\n",
    "    else:\n",
    "        transect_sheet[\"TransectUID\"] = pd.NA\n",
    "\n",
    "transect_sheet[\"TransectUID\"] = pd.to_numeric(transect_sheet[\"TransectUID\"], errors=\"coerce\").astype(\"Int64\")\n",
    "mni_per_transect[\"TransectUID\"] = pd.to_numeric(mni_per_transect[\"TransectUID\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "transect_sheet = transect_sheet.merge(mni_per_transect, on=\"TransectUID\", how=\"left\")\n",
    "transect_sheet = transect_sheet.rename(columns={\"MNI\": \"MNI_calc\"})\n",
    "\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "if output_path.exists():\n",
    "    with pd.ExcelWriter(output_path, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
    "        transect_sheet.to_excel(writer, sheet_name=\"Transects\", index=False)\n",
    "else:\n",
    "    with pd.ExcelWriter(output_path, engine=\"openpyxl\") as writer:\n",
    "        transect_sheet.to_excel(writer, sheet_name=\"Transects\", index=False)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}