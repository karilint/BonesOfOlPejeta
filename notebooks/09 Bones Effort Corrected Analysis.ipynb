{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e841fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scipy seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2f57a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: Indicator species analysis with effort- and detection-corrected densities\n",
    "# Each step below is commented to describe the workflow clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e5dd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and filter data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the pickled data generated in previous notebooks\n",
    "df_transects = pd.read_pickle('../data/pkl/df_transects.pkl')\n",
    "df_occurrences = pd.read_pickle('../data/pkl/df_occurrences_with_taxon.pkl')\n",
    "\n",
    "# Filter transects excluding year 2008 and most 2024 transects (keep 2024 'shrubs closed')\n",
    "# and keep only those on the old reserve\n",
    "df_transects['Year'] = pd.to_datetime(df_transects['start_time']).dt.year\n",
    "mask_not_2008 = df_transects['Year'] != 2008\n",
    "mask_keep_2024 = ~((df_transects['Year'] == 2024) & (df_transects['Pre: Transect physical habitat'] != 'shrubs closed'))\n",
    "df_filtered_transects = df_transects[mask_not_2008 & mask_keep_2024].copy()\n",
    "df_filtered_transects = df_filtered_transects[df_filtered_transects['Pre: On old reserve?'] == 'Yes'].copy()\n",
    "\n",
    "# Standardize column names for ease of merging\n",
    "rename_transects = {'UID': 'TransectID', 'Pre: Transect physical habitat': 'Habitat'}\n",
    "df_filtered_transects = df_filtered_transects.rename(columns=rename_transects)\n",
    "\n",
    "# Prepare occurrences: standardize fields and restrict to filtered transects\n",
    "rename_occ = {'UID': 'TransectID', 'Taxon Label': 'Taxon'}\n",
    "df_occurrences = df_occurrences.rename(columns=rename_occ)\n",
    "df_occurrences = df_occurrences[df_occurrences['TransectID'].isin(df_filtered_transects['TransectID'])]\n",
    "\n",
    "# Remove broad or unwanted taxa\n",
    "excluded_species = ['ostrich', 'Aves (medium)', 'Aves (small)']\n",
    "df_occurrences = df_occurrences[~df_occurrences['Taxon'].isin(excluded_species)]\n",
    "\n",
    "# Attach habitat and transect-length info to occurrences\n",
    "df_occurrences = df_occurrences.merge(\n",
    "    df_filtered_transects[['TransectID', 'Habitat', 'distance_km']],\n",
    "    on='TransectID',\n",
    "    how='left',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc19c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define survey width and effective strip width (ESW)\n",
    "# Observers walked side by side covering a 50 m strip, so recorded distances\n",
    "# are not suitable for fitting a detection function. We assume perfect detection\n",
    "# within this strip, yielding an ESW equal to half the strip width.\n",
    "\n",
    "TRANSECT_WIDTH_M = 50  # total search width in meters\n",
    "ESW_m = TRANSECT_WIDTH_M / 2\n",
    "print(f\"Assumed ESW (m): {ESW_m}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac7ef80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Compute effort-corrected densities\n",
    "# Use transect-specific lengths and the fixed strip width to derive searched area.\n",
    "# Density for a taxon on a transect is Count / searched area.\n",
    "\n",
    "df_filtered_transects['TransectLength_m'] = df_filtered_transects['distance_km'] * 1000\n",
    "df_filtered_transects['SearchedArea_m2'] = df_filtered_transects['TransectLength_m'] * TRANSECT_WIDTH_M\n",
    "\n",
    "# Count occurrences per transect, habitat and taxon\n",
    "transect_taxon_counts = (\n",
    "    df_occurrences.groupby(['TransectID', 'Habitat', 'Taxon']).size().reset_index(name='Count')\n",
    ")\n",
    "\n",
    "# Merge with searched area and compute density\n",
    "transect_taxon_counts = transect_taxon_counts.merge(\n",
    "    df_filtered_transects[['TransectID', 'SearchedArea_m2']],\n",
    "    on='TransectID',\n",
    "    how='left'\n",
    ")\n",
    "transect_taxon_counts['Density_per_m2'] = (\n",
    "    transect_taxon_counts['Count'] / transect_taxon_counts['SearchedArea_m2']\n",
    ")\n",
    "\n",
    "transect_taxon_counts.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990a1e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create habitat × taxon density matrix\n",
    "# We aggregate densities by habitat to get average detection-corrected density per taxon.\n",
    "\n",
    "df_density_matrix = (\n",
    "    transect_taxon_counts.groupby([\"Habitat\", \"Taxon\"]).agg(\n",
    "        Density_per_m2=(\"Density_per_m2\", \"mean\")\n",
    "    ).reset_index()\n",
    ")\n",
    "\n",
    "# Pivot to matrix form: rows = habitats, columns = taxa, values = density\n",
    "\n",
    "df_matrix = df_density_matrix.pivot(\n",
    "    index=\"Habitat\", columns=\"Taxon\", values=\"Density_per_m2\"\n",
    ").fillna(0)\n",
    "\n",
    "df_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efac6ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Indicator Species Analysis on detection-corrected densities\n",
    "# Apply the Dufrêne-Legendre IndVal method with permutation-based p-values.\n",
    "\n",
    "# Convert to presence/absence if required by the analysis\n",
    "# Here we keep densities, but you could binarize by replacing >0 with 1.\n",
    "\n",
    "def compute_indval(df, groups, n_permutations=999, random_state=0):\n",
    "    \"\"\"Compute IndVal and permutation-based p-values for each species.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Species densities with habitats as index and species as columns.\n",
    "    groups : list-like\n",
    "        Group label for each row in `df` (e.g., habitat names).\n",
    "    n_permutations : int\n",
    "        Number of random permutations to derive p-values.\n",
    "    random_state : int\n",
    "        Seed for the random number generator.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    groups = np.asarray(groups)\n",
    "    group_names = np.unique(groups)\n",
    "    results = []\n",
    "\n",
    "    for species in df.columns:\n",
    "        species_data = df[species].to_numpy()\n",
    "        indvals = []\n",
    "        for g in group_names:\n",
    "            mask = groups == g\n",
    "            A = species_data[mask].mean()  # specificity\n",
    "            B = (species_data[mask] > 0).mean()  # fidelity\n",
    "            indvals.append(A * B)\n",
    "        max_indval = float(np.max(indvals))\n",
    "        best_group = group_names[int(np.argmax(indvals))]\n",
    "\n",
    "        # Permutation test for p-value\n",
    "        permuted_max = []\n",
    "        for _ in range(n_permutations):\n",
    "            shuffled = rng.permutation(groups)\n",
    "            perm_indvals = []\n",
    "            for g in group_names:\n",
    "                mask = shuffled == g\n",
    "                A = species_data[mask].mean()\n",
    "                B = (species_data[mask] > 0).mean()\n",
    "                perm_indvals.append(A * B)\n",
    "            permuted_max.append(np.max(perm_indvals))\n",
    "        permuted_max = np.asarray(permuted_max)\n",
    "        p_val = (np.sum(permuted_max >= max_indval) + 1) / (n_permutations + 1)\n",
    "\n",
    "        results.append({\"Species\": species, \"Habitat\": best_group, \"IndVal\": max_indval, \"p_value\": p_val})\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Group labels correspond to the habitat names\n",
    "habitats = df_matrix.index.to_list()\n",
    "\n",
    "df_indicators = compute_indval(df_matrix, habitats)\n",
    "\n",
    "# Sort and inspect the top indicator species\n",
    "df_indicators.sort_values(\"IndVal\", ascending=False).head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
